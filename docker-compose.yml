# =============================================================================
# fin-risk-engine — local development stack
#
# Services:
#   api     — FastAPI + Gradio scoring API   → http://localhost:8000
#   mlflow  — MLflow experiment browser      → http://localhost:5000
#
# Usage:
#   docker compose up -d          # start all services
#   docker compose logs -f api    # stream API logs
#   docker compose down           # stop all services
#
# Prerequisites:
#   1. Build (or train) model artifacts:  make train-all && make evaluate
#   2. Build image:                       make docker-build
# =============================================================================

services:
  # ── Fraud scoring API (FastAPI + Gradio) ────────────────────────────────────
  api:
    build: .
    image: fin-risk-engine:latest
    ports:
      - "8000:8000"
    volumes:
      # Model artifacts and calibrators (generated by make train-all + make evaluate)
      - ./outputs:/app/outputs
      # MLflow SQLite DB + model registry (generated by make train-all)
      - ./mlruns:/app/mlruns
    environment:
      PYTHONPATH: /app
    healthcheck:
      test: ["CMD", "curl", "-sf", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      start_period: 60s
      retries: 3
    restart: unless-stopped

  # ── MLflow experiment browser ────────────────────────────────────────────────
  mlflow:
    image: fin-risk-engine:latest
    command: >
      mlflow ui
      --backend-store-uri sqlite:///mlruns/mlflow.db
      --host 0.0.0.0
      --port 5000
    ports:
      - "5000:5000"
    volumes:
      - ./mlruns:/app/mlruns
    restart: unless-stopped
